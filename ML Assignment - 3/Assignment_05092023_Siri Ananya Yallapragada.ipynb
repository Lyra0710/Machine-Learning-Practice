{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 3 (5th August, 2023)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task: \n",
    "#### Take any dataset (numerical or categorical). Apply basic generic decision tree algorithm, apply any two spliting criteria and show the difference in evaluation metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CustomerID</th>\n",
       "      <th>Age</th>\n",
       "      <th>Annual Income ($)</th>\n",
       "      <th>Spending Score (1-100)</th>\n",
       "      <th>Work Experience</th>\n",
       "      <th>Family Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1000.500000</td>\n",
       "      <td>48.960000</td>\n",
       "      <td>110731.821500</td>\n",
       "      <td>50.962500</td>\n",
       "      <td>4.102500</td>\n",
       "      <td>3.768500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>577.494589</td>\n",
       "      <td>28.429747</td>\n",
       "      <td>45739.536688</td>\n",
       "      <td>27.934661</td>\n",
       "      <td>3.922204</td>\n",
       "      <td>1.970749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>500.750000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>74572.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1000.500000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>110045.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1500.250000</td>\n",
       "      <td>73.000000</td>\n",
       "      <td>149092.750000</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2000.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>189974.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        CustomerID          Age  Annual Income ($)  Spending Score (1-100)  \\\n",
       "count  2000.000000  2000.000000        2000.000000             2000.000000   \n",
       "mean   1000.500000    48.960000      110731.821500               50.962500   \n",
       "std     577.494589    28.429747       45739.536688               27.934661   \n",
       "min       1.000000     0.000000           0.000000                0.000000   \n",
       "25%     500.750000    25.000000       74572.000000               28.000000   \n",
       "50%    1000.500000    48.000000      110045.000000               50.000000   \n",
       "75%    1500.250000    73.000000      149092.750000               75.000000   \n",
       "max    2000.000000    99.000000      189974.000000              100.000000   \n",
       "\n",
       "       Work Experience  Family Size  \n",
       "count      2000.000000  2000.000000  \n",
       "mean          4.102500     3.768500  \n",
       "std           3.922204     1.970749  \n",
       "min           0.000000     1.000000  \n",
       "25%           1.000000     2.000000  \n",
       "50%           3.000000     4.000000  \n",
       "75%           7.000000     5.000000  \n",
       "max          17.000000     9.000000  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"Customers.csv\")\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CustomerID                 0\n",
       "Gender                     0\n",
       "Age                        0\n",
       "Annual Income ($)          0\n",
       "Spending Score (1-100)     0\n",
       "Profession                35\n",
       "Work Experience            0\n",
       "Family Size                0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gini_impurity(labels):\n",
    "    total_samples = len(labels)\n",
    "    unique_labels, label_counts = np.unique(labels, return_counts=True)\n",
    "    probabilities = label_counts / total_samples\n",
    "    gini = 1 - sum(probabilities ** 2)\n",
    "    return gini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy(labels):\n",
    "    total_samples = len(labels)\n",
    "    unique_labels, label_counts = np.unique(labels, return_counts=True)\n",
    "    probabilities = label_counts / total_samples\n",
    "    entropy = -sum(probabilities * np.log2(probabilities))\n",
    "    return entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(data, feature, threshold):\n",
    "    left_data = data[data[feature] <= threshold]\n",
    "    right_data = data[data[feature] > threshold]\n",
    "    return left_data, right_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_impurity(data, criterion):\n",
    "    labels = data['Spending Score (1-100)']  # Replace 'Target' with your actual target column name\n",
    "    if criterion == 'gini':\n",
    "        impurity = gini_impurity(labels)\n",
    "    elif criterion == 'entropy':\n",
    "        impurity = entropy(labels)\n",
    "    return impurity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_split(data, criterion):\n",
    "    best_split = {'feature': None, 'threshold': None, 'impurity': float('inf')}\n",
    "    \n",
    "    for feature in data.columns:\n",
    "        if feature == 'Spending Score (1-100)':  # Skip the target column\n",
    "            continue\n",
    "        \n",
    "        for threshold in data[feature].unique():\n",
    "            left_data, right_data = split_data(data, feature, threshold)\n",
    "            total_impurity = (len(left_data) / len(data)) * calculate_impurity(left_data, criterion) + \\\n",
    "                             (len(right_data) / len(data)) * calculate_impurity(right_data, criterion)\n",
    "            \n",
    "            if total_impurity < best_split['impurity']:\n",
    "                best_split['feature'] = feature\n",
    "                best_split['threshold'] = threshold\n",
    "                best_split['impurity'] = total_impurity\n",
    "    \n",
    "    return best_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_decision_tree(data, criterion, max_depth):\n",
    "    if max_depth == 0 or len(data['Spending Score (1-100)'].unique()) == 1:\n",
    "        return data['Spending Score (1-100)'].mode().iloc[0]\n",
    "    \n",
    "    best_split = find_best_split(data, criterion)\n",
    "    if best_split['impurity'] == 0:\n",
    "        return data['Spending Score (1-100)'].mode().iloc[0]\n",
    "    \n",
    "    left_data, right_data = split_data(data, best_split['feature'], best_split['threshold'])\n",
    "    \n",
    "    left_subtree = build_decision_tree(left_data, criterion, max_depth - 1)\n",
    "    right_subtree = build_decision_tree(right_data, criterion, max_depth - 1)\n",
    "    \n",
    "    return {'feature': best_split['feature'],\n",
    "            'threshold': best_split['threshold'],\n",
    "            'left': left_subtree,\n",
    "            'right': right_subtree}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_tree_accuracy(tree, data):\n",
    "    correct = 0\n",
    "    total = len(data)\n",
    "    \n",
    "    for index, row in data.iterrows():\n",
    "        prediction = predict(tree, row)\n",
    "        if prediction == row['Spending Score (1-100)']:\n",
    "            correct += 1\n",
    "    \n",
    "    accuracy = correct / total\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(tree, data):\n",
    "    if isinstance(tree, dict):\n",
    "        feature = tree['feature']\n",
    "        threshold = tree['threshold']\n",
    "        if data[feature] <= threshold:\n",
    "            return predict(tree['left'], data)\n",
    "        else:\n",
    "            return predict(tree['right'], data)\n",
    "    else:\n",
    "        return tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assuming 'Target' is the name of the target variable\n",
    "X = data.drop(columns=['Spending Score (1-100)'])\n",
    "y = data['Spending Score (1-100)']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize lists to store accuracy values for Gini and Entropy criteria\n",
    "accuracy_gini = []\n",
    "accuracy_entropy = []\n",
    "\n",
    "# Evaluate decision trees for different depths and record accuracy\n",
    "max_depth_range = range(1, 10)  # Adjust the range as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Spending Score (1-100)'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\indexes\\base.py:3802\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3801\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 3802\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[0;32m   3803\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\_libs\\index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\_libs\\index.pyx:165\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5745\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5753\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Spending Score (1-100)'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mfor\u001b[39;00m max_depth \u001b[39min\u001b[39;00m max_depth_range:\n\u001b[0;32m      2\u001b[0m     \u001b[39m# Build decision trees for both criteria\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m     decision_tree_gini \u001b[39m=\u001b[39m build_decision_tree(X_train, \u001b[39m'\u001b[39;49m\u001b[39mgini\u001b[39;49m\u001b[39m'\u001b[39;49m, max_depth)\n\u001b[0;32m      4\u001b[0m     decision_tree_entropy \u001b[39m=\u001b[39m build_decision_tree(X_train, \u001b[39m'\u001b[39m\u001b[39mentropy\u001b[39m\u001b[39m'\u001b[39m, max_depth)\n\u001b[0;32m      6\u001b[0m     \u001b[39m# Evaluate and record accuracy for Gini and Entropy criteria\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[24], line 2\u001b[0m, in \u001b[0;36mbuild_decision_tree\u001b[1;34m(data, criterion, max_depth)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mbuild_decision_tree\u001b[39m(data, criterion, max_depth):\n\u001b[1;32m----> 2\u001b[0m     \u001b[39mif\u001b[39;00m max_depth \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m \u001b[39mor\u001b[39;00m \u001b[39mlen\u001b[39m(data[\u001b[39m'\u001b[39;49m\u001b[39mSpending Score (1-100)\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39munique()) \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m      3\u001b[0m         \u001b[39mreturn\u001b[39;00m data[\u001b[39m'\u001b[39m\u001b[39mSpending Score (1-100)\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mmode()\u001b[39m.\u001b[39miloc[\u001b[39m0\u001b[39m]\n\u001b[0;32m      5\u001b[0m     best_split \u001b[39m=\u001b[39m find_best_split(data, criterion)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\frame.py:3807\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3805\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   3806\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3807\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[0;32m   3808\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3809\u001b[0m     indexer \u001b[39m=\u001b[39m [indexer]\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\indexes\\base.py:3804\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3802\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3803\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m-> 3804\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[0;32m   3805\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m   3806\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3807\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3808\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3809\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Spending Score (1-100)'"
     ]
    }
   ],
   "source": [
    "for max_depth in max_depth_range:\n",
    "    # Build decision trees for both criteria\n",
    "    decision_tree_gini = build_decision_tree(X_train, 'gini', max_depth)\n",
    "    decision_tree_entropy = build_decision_tree(X_train, 'entropy', max_depth)\n",
    "    \n",
    "    # Evaluate and record accuracy for Gini and Entropy criteria\n",
    "    accuracy_gini.append(evaluate_tree_accuracy(decision_tree_gini, X_test))\n",
    "    accuracy_entropy.append(evaluate_tree_accuracy(decision_tree_entropy, X_test))\n",
    "\n",
    "# Plot the accuracy comparison\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(max_depth_range, accuracy_gini, marker='o', label='Gini Impurity')\n",
    "plt.plot(max_depth_range, accuracy_entropy, marker='o', label='Entropy')\n",
    "plt.xlabel('Max Depth of Decision Tree')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Accuracy Comparison: Gini vs. Entropy')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
